{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589a4b7e-4184-4c43-ac36-e2791f08f8bc",
   "metadata": {
    "id": "589a4b7e-4184-4c43-ac36-e2791f08f8bc",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<hr style=\"height: 1px;\">\n",
    "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h1>Pset 4: Problems Using Numerical Simulation Part II</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b809e",
   "metadata": {
    "id": "7d8b809e",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_4_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.0 Overview</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc477952",
   "metadata": {
    "id": "fc477952",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<h3>Navigation</h3>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_5\">P4.5 Galaxy Rotation Curves</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_5\">P4.5 Problems</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_6\">P4.6 Training a NN to Find Tau Leptons</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_6\">P4.6 Problems</a></td>\n",
    "    </tr>    \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cf1d4",
   "metadata": {
    "id": "178cf1d4",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Learning Objectives</h3>\n",
    "\n",
    "In this Pset, we will simulate a galaxy and, from this simuilation, we will then compute rotation curves. We will also explore NN modeling of Tau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ada12",
   "metadata": {
    "id": "5cf300ff",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Importing Libraries</h3>\n",
    "\n",
    "Before beginning, run the cell below to import the relevant libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdc10f",
   "metadata": {
    "id": "06bdc10f",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: P4.0-runcell00\n",
    "\n",
    "#install the following if you have note done so:\n",
    "\n",
    "#!pip install imageio\n",
    "#!pip3 install torch torchvision torchaudio\n",
    "#!pip install lmfit\n",
    "#!pip install uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10940911",
   "metadata": {
    "id": "06bdc10f",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: P4.0-runcell01\n",
    "\n",
    "import itertools\n",
    "from IPython.display import HTML\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305bb60",
   "metadata": {
    "id": "2305bb60",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Setting Default Figure Parameters</h3>\n",
    "\n",
    "The following code cell sets default values for figure parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957ae03",
   "metadata": {
    "id": "f957ae03",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: P4.0-runcell02\n",
    "\n",
    "#set plot resolution\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#set default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "medium_size = 12\n",
    "large_size = 15\n",
    "\n",
    "plt.rc('font', size=medium_size)          # default text sizes\n",
    "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n",
    "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n",
    "plt.rc('legend', fontsize=medium_size)    # legend\n",
    "plt.rc('axes', titlesize=large_size)      # axes title\n",
    "plt.rc('axes', labelsize=large_size)      # x and y labels\n",
    "plt.rc('figure', titlesize=large_size)    # figure title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XwglZZ6LqSnq",
   "metadata": {
    "id": "XwglZZ6LqSnq",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<!--start-block-->\n",
    "<a name='section_4_5'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.5 Galaxy Rotation Curves\n",
    "\n",
    "| [Top](#section_4_0) | [Previous Section](#section_4_0) | [Problems](#problems_4_5) | [Next Section](#section_4_6) | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jc3qLAdIqahZ",
   "metadata": {
    "id": "Jc3qLAdIqahZ",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "In this problem, we are going to make a simulation of a galaxy, from this simuilation, we will then compute rotation curves. The we will modify the simulation, adding two populations, visible matter, and dark matter. Then we will see how we can emulate the behavior of rotation curves.\n",
    "\n",
    "Lastly, we will investigate how to bring this to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fsk42vdUqZEL",
   "metadata": {
    "id": "Fsk42vdUqZEL",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Units\n",
    "Gc=39.478 #AU^3/yr^2/Msun\n",
    "re=1.0#AU\n",
    "ve=2*np.pi*re#2pir/yr\n",
    "Gmod=Gc/re**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WTAeMfNMqt5r",
   "metadata": {
    "id": "WTAeMfNMqt5r",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3> Basic Setup </h3>\n",
    "\n",
    "Lets start by seeing how a galaxy forms. To do that, lets randomly place in a uniform distribution of stars, and then evolve it under forces of gravity. For the first part of this problem, we will use the parallelized part of the star evolution, as oppose to the tree structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62615de1",
   "metadata": {
    "id": "fe08ba86",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='problems_4_5'></a>     \n",
    "\n",
    "| [Top](#section_4_0) | [Restart Section](#section_4_5) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tb8rYTDXqy6C",
   "metadata": {
    "id": "Tb8rYTDXqy6C",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.1</span>\n",
    "\n",
    "In the code below, add the force equations and computation of $\\Delta r^2_{ij}=\\Delta x_{ij}^2 + \\Delta y_{ij}^2 + \\epsilon^2$ matrix that builds on the $\\Delta r$ computation. Be sure to add the softening term $\\epsilon$.\n",
    "\n",
    "Then run the subsequent code after this problem to create the visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286z8tNQqlcL",
   "metadata": {
    "id": "286z8tNQqlcL",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.1\n",
    "\n",
    "#this function computes the force and potential energy of the system\n",
    "def forcefunction_base(iR,iMass,iSofen):\n",
    "    xpos=iR[:,0:1]\n",
    "    ypos=iR[:,1:2]\n",
    "    dx = xpos.T - xpos\n",
    "    dy = ypos.T - ypos\n",
    "    dr2  = #Add your own code, be sure to add softening\n",
    "    dr1        = dr2**(-0.5)\n",
    "    dr2[dr2>0] = dr2[dr2>0]**(-1.5)\n",
    "    ax   = #Add your own code\n",
    "    ay   = #Add your own code\n",
    "    a = np.hstack((ax,ay))\n",
    "    pot = #Add your own code to compute the potential Energy\n",
    "    return a,pot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27276a",
   "metadata": {
    "id": "WTAeMfNMqt5r",
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Define the Visualization</h3>\n",
    "\n",
    "Having completed the code for `forcefunction`, run the cell below to define our visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc38e42",
   "metadata": {
    "id": "286z8tNQqlcL",
    "tags": [
     "py",
     "learner_chopped",
     "learner"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "###Visualiztion code\n",
    "def makePlot(nbody,coords,ax,fig,images,ymin=-2,ymax=2,xmin=-2,xmax=2):\n",
    "    # plot and show learning process\n",
    "    plt.cla()\n",
    "    ax.set_xlabel('x(AU)', fontsize=24)\n",
    "    ax.set_ylabel('y(AU)', fontsize=24)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    for body in range(nbody):\n",
    "        ax.plot(np.flip(coords[body][:,0]),np.flip(coords[body][:,1]), 'o-',color = '#d2eeff',markevery=10000, markerfacecolor = '#0077BE',lw=2)\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "def animate(coords,iN=2,ymin=-10,ymax=10,xmin=-10,xmax=10,stepsize=50):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % stepsize == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images,ymin=ymin,ymax=ymax,xmin=xmin,xmax=xmax)\n",
    "    return images\n",
    "\n",
    "\n",
    "class AllStars:\n",
    "    def __init__(self,iX,iV,iM,ibase=True,isoften=1e-2):\n",
    "        self.rpos = iX\n",
    "        self.v    = iV\n",
    "        self.mass = iM\n",
    "        self.n    = len(iX)\n",
    "        self.posh   = []\n",
    "        self.velh   = []\n",
    "        self.enh    = []\n",
    "        self.nsteps = 0\n",
    "        self.soften = isoften\n",
    "        self.base   = ibase\n",
    "\n",
    "    def force(self): #take in arrays of everything\n",
    "        if self.base:\n",
    "            self.a,self.pot = forcefunction_base(self.rpos,self.mass,self.soften)\n",
    "        else:\n",
    "            self.a,self.pot = forcefunction(self.rpos,self.mass,self.soften)\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        self.v    = self.v   +0.5*dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "\n",
    "    def step(self,dt):\n",
    "        self.v    = self.v   +dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "\n",
    "    def store(self):\n",
    "        lXs = self.rpos\n",
    "        self.posh.append(lXs)\n",
    "        lVs = self.v\n",
    "        self.velh.append(lVs)\n",
    "        lV2 = np.reshape((lVs[:,0]**2+lVs[:,1]**2),(self.n,1))\n",
    "        lEn = 0.5*self.mass*lV2 + 0.5*self.mass *self.pot ## Missing 0.5 on potential added after office hours 4/16\n",
    "        self.enh.append(lEn)\n",
    " \n",
    "    def points(self):\n",
    "        return self.rpos\n",
    "\n",
    "    def history(self):\n",
    "        return np.reshape(np.array([self.posh]),(self.nsteps,self.n,2))\n",
    "\n",
    "    def velhistory(self):\n",
    "        return np.reshape(np.array([self.velh]),(self.nsteps,self.n,2))\n",
    "\n",
    "    def enhistory(self):\n",
    "        return np.reshape(np.array([self.enh]),(self.nsteps,self.n))\n",
    "\n",
    "    def allsteps(self,insteps=5000,dt=0.001):\n",
    "        nsteps=insteps\n",
    "        self.nsteps+=nsteps\n",
    "        self.force()\n",
    "        self.firststep(dt)\n",
    "        for t in range(nsteps):\n",
    "            self.force()\n",
    "            self.step(dt)\n",
    "            self.store()\n",
    "        return self.points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5i8sOccs0QM",
   "metadata": {
    "id": "N5i8sOccs0QM",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.2</span>\n",
    "\n",
    "Now lets check if this code makes sense. Perform a 2-body simulation for a circular orbit of a binary star, each having a solar mass and radius of 1 Au. Note that,\n",
    "\n",
    "$$\\frac{\\mu v^2}{r } = \\frac{GM_{1}M_{2}}{r^2}$$\n",
    "\n",
    "What is the timestep `dt` where the simulation breaks down? Enter a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VeELUysRskR9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "VeELUysRskR9",
    "outputId": "7de157c6-8e2b-478c-9c94-087d76a139e3",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.2\n",
    "\n",
    "np.random.seed(1234)\n",
    "nStar=2\n",
    "X = np.zeros((nStar, 2))\n",
    "V = np.zeros((nStar, 2))\n",
    "M = np.ones((nStar,1))\n",
    "\n",
    "vcircle = #YOUR CODE HERE\n",
    "\n",
    "X[0,0] =  1\n",
    "X[1,0] = -1\n",
    "V[0,1] =  vcircle*0.5\n",
    "V[1,1] = -vcircle*0.5\n",
    "\n",
    "allStar = AllStars(X,V,M)\n",
    "Xout=allStar.allsteps(insteps=5000,dt=1e-3) ###for what dt does this stops working?\n",
    "\n",
    "tracks=allStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "images=animate(tracks,iN=nStar,xmin=-2,xmax=2,ymin=-2,ymax=2,stepsize=100)\n",
    "imageio.mimsave('./orbit_n_v2_v1.gif', images, fps=10)\n",
    "Image(open('orbit_n_v2_v1.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8h0YMO37uwhp",
   "metadata": {
    "id": "8h0YMO37uwhp",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.3</span>\n",
    "\n",
    "Now, we want to make a realistic galaxy simulation so that we can study how galaxies form and ultimately make some rotation curves. Let's start by randomly sampling stars in a rectangular grid of with 20000 x 20000 astronomical units; for starters we can sample 50 stars and evolve it. The typical density of stars at the center of a galaxy is about 1 star per 500 astronomical units, which equates to about 20 times the density we consider here.\n",
    "\n",
    "Run this simulation in two modes, first run this in a mode where you can make sure the motion makes sense (1000 steps or so), choose an appropriate time step and soften parameter. Then, when you are happy, run this for a long period (1 Million years or so). This long simulation will allow us to understand galaxy evolution.  \n",
    "\n",
    "To see how the galaxy is formed randomly sample the stars and evolve it.  \n",
    "\n",
    "What happens to the center of mass and angular momentum of the system? Select ALL that apply.\n",
    "\n",
    "A) center of mass stays the same\\\n",
    "B) center of mass changes\\\n",
    "C) angular momentum stays the same\\\n",
    "D) angular momentum changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wB3ZshBps_QN",
   "metadata": {
    "id": "wB3ZshBps_QN",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.3\n",
    "\n",
    "#First we will sample 3000 stars in 2D space with 2D velocity\n",
    "nStar=50\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = #YOUR CODE HERE\n",
    "\n",
    "V = np.zeros((nStar, 2))\n",
    "M = np.ones((nStar,1))\n",
    "\n",
    "#ADJUST THE SIMULATION BELOW\n",
    "allStar = AllStars(X,V,M,isoften=1e3)\n",
    "Xout=allStar.allsteps(insteps=40000,dt=25.)\n",
    "tracks=allStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "images=animate(tracks,iN=nStar,xmin=-4e4,xmax=4e4,ymin=-4e4,ymax=4e4,stepsize=100)\n",
    "imageio.mimsave('./orbit_n.gif', images, fps=10)\n",
    "Image(open('orbit_n.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trUDvb8kJvAC",
   "metadata": {
    "id": "trUDvb8kJvAC",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.4</span>\n",
    "\n",
    "First lets run some common sense checks of our simulation. We want to know:\n",
    "\n",
    "A) What is the max change in the center of mass of the total system?  \n",
    "\n",
    "B) What is the change in velocity of the system?\n",
    "\n",
    "C) What is the change in the angular of momentum of the total system from beginning to end?\n",
    "\n",
    "D) What is the change in energy?\n",
    "\n",
    "Determine the order-of-magnitude answers to the above questions (for instance, `2.567e-10` would be expressed as `1e-10`, `7.567e-10` would be expressed as `1e-9`, and `2.567` would be expressed as `1e1`, etc.). Report your results as a list of numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PYAfD2w5vTHy",
   "metadata": {
    "id": "PYAfD2w5vTHy",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.4\n",
    "\n",
    "def centerOfMass(iVec):\n",
    "    center = #YOUR CODE HERE: compute center of mass\n",
    "    return center\n",
    "\n",
    "def angMomentun(iR,iV):\n",
    "    center = centerOfMass(iR)\n",
    "    shift = #YOUR CODE HERE: Shift coordinates by center\n",
    "    ang = #YOUR CODE HERE: angular mometnum\n",
    "    return np.sum(ang,axis=0)\n",
    "\n",
    "tracks=allStar.history()\n",
    "comX0=centerOfMass(tracks[0])\n",
    "comX1=centerOfMass(tracks[-1])\n",
    "print(\"com0\",comX0,\"com1\",comX1)\n",
    "print(\"delta_com\", np.sqrt(np.sum((comX1 - comX0)**2.)))\n",
    "print()\n",
    "\n",
    "veltracks=allStar.velhistory()\n",
    "vcomX0=centerOfMass(veltracks[0])\n",
    "vcomX1=centerOfMass(veltracks[-1])\n",
    "print(\"vel com0\",vcomX0,\"vel com1\",vcomX1)\n",
    "print(\"delta_com_vel\", np.sqrt(np.sum((vcomX1 - vcomX0)**2.)))\n",
    "print()\n",
    "\n",
    "LcomX0=angMomentun(tracks[0],veltracks[0])\n",
    "LcomX1=angMomentun(tracks[-1],veltracks[-1])\n",
    "print(\"L com0\",LcomX0,\"L com1\",LcomX1)\n",
    "print(\"delta_com_L\", abs(LcomX1 - LcomX0))\n",
    "print()\n",
    "\n",
    "enhist=allStar.enhistory()\n",
    "enhisttot=np.sum(enhist,axis=1)\n",
    "E0 = enhisttot[0]\n",
    "E1 = enhisttot[-1]\n",
    "print(\"E tot\",E0,\"E final\",E1)\n",
    "print(\"delta_E\", abs(E1 - E0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0655a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "rlGeizsRJ2YH",
    "outputId": "81fbdeb5-d6a3-4806-c8e9-eec2502c09d3",
    "tags": [
     "py",
     "learner",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "##Now some fun plots\n",
    "def centerOfMassTime(iVec):\n",
    "    center=np.sum(iVec,axis=1)/iVec.shape[1]\n",
    "    return center\n",
    "\n",
    "def shiftCOM(iR):\n",
    "    center=centerOfMassTime(iR)\n",
    "    shift=iR\n",
    "    for pVal in range(iR.shape[1]):\n",
    "        shift[:,pVal] -= center\n",
    "    return shift\n",
    "\n",
    "def angMomentumTime(iR,iV):\n",
    "    shift=shiftCOM(iR)\n",
    "    ang=shift[:,:,0]*iV[:,:,1]-shift[:,:,1]*iV[:,:,0]\n",
    "    return np.sum(ang,axis=1)\n",
    "    \n",
    "\n",
    "Ltime=angMomentumTime(tracks,veltracks)\n",
    "plt.plot(Ltime)\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"L\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(enhisttot)\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"E\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bBCr9cr3KuU7",
   "metadata": {
    "id": "bBCr9cr3KuU7",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.5</span>\n",
    "\n",
    "Now that we have answered the basic questions, lets go ahead and try to come up with a more detailed analytic answer. Given our above simulation, write a script to show the average density before and after the simulation. Roughly what fraction of stars are > 10k AU before evolving. What fraction are  > 10k after at least 1 Million years of evolution. Report your answer as a list of two numbers, `[frac_before, frac_after]`, with precision `1e-2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5IDA3pe8J3Ij",
   "metadata": {
    "id": "5IDA3pe8J3Ij",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.5\n",
    "\n",
    "def makeRadiusHist(iX):\n",
    "    shift=shiftCOM(iX)\n",
    "    evts,bin_edges=np.histogram(np.sqrt(shift[:,0]**2+shift[:,1]**2),bins=10,range=[0,2e4],density=True)\n",
    "    bin_centers=0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    return bin_centers,evts\n",
    "\n",
    "def plotRadius(iTracks):\n",
    "    pX0,pY0 = makeRadiusHist(iTracks[0])\n",
    "    plt.plot(pX0,pY0,drawstyle = 'steps-mid',label='start',c='blue')\n",
    "    pX1,pY1 = makeRadiusHist(iTracks[-1])\n",
    "    plt.plot(pX1,pY1,drawstyle = 'steps-mid',label='end',c='red')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"r(AU)\")\n",
    "    plt.ylabel(\"N\")\n",
    "    plt.show()\n",
    "\n",
    "plotRadius(tracks)\n",
    "\n",
    "#now density => each bin divide by r => rho=N/2pirdr\n",
    "pX0,pY0 = makeRadiusHist(tracks[0])\n",
    "pX1,pY1 = makeRadiusHist(tracks[-1])\n",
    "plt.plot(pX0,pY0/pX0,drawstyle = 'steps-mid',label='start',c='blue')\n",
    "plt.plot(pX1,pY1/pX1,drawstyle = 'steps-mid',label='end',c='red')\n",
    "plt.legend()\n",
    "plt.xlabel(\"r(AU)\")\n",
    "plt.ylabel(\"rho\")\n",
    "plt.show()\n",
    "\n",
    "def fraction(iX,iR=50000):\n",
    "    ## YOUR CODE HERE\n",
    "    return frac\n",
    "\n",
    "frc0=fraction(tracks[0])\n",
    "frc1=fraction(tracks[-1])\n",
    "print(\"Fraction:\",frc0,\" Updated Fraction\",frc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475e280",
   "metadata": {
    "id": "bBCr9cr3KuU7",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.6</span>\n",
    "\n",
    "Now lets start to look at how the galaxy evolves. Plot the average radial velocity vs. radius of the toy galaxy what is the average radial velocity of the inner 80% compared to the last 20%? Report your answer as a list of two numbers, `[vel_inner, vel_outer]` with units of AU/year, with precision `1e-1`. Just gauge by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c60aa",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.6\n",
    "\n",
    "def plotRvsV(iR,iV,iNbins=5): \n",
    "    #Sort data array in R\n",
    "    sort = #get sorted indices\n",
    "    #split data into nbins\n",
    "    corrXsort = iR[sort]\n",
    "    corrYsort = iV[sort]\n",
    "    ncands=len(iV)//iNbins\n",
    "    corrXsort = np.reshape(corrXsort,(iNbins,ncands))\n",
    "    corrXmean = np.mean(corrXsort,axis=1)\n",
    "    corrXrms  = np.std(corrXsort,axis=1)/np.sqrt(ncands)\n",
    "\n",
    "    corrYsort = np.reshape(corrYsort,(iNbins,ncands))\n",
    "    corrYmean = #compute Ysort mean in bins (see hint above)\n",
    "    corrYrms  = #compute Ysort std in bins\n",
    "    return corrXmean,corrYmean,corrXrms,corrYrms\n",
    "\n",
    "##Now some fun plots\n",
    "def shiftCOM(iR):\n",
    "    center=#compute center of mass\n",
    "    shift=iR\n",
    "    #shift it\n",
    "    for pVal in range(iR.shape[0]):\n",
    "        shift[pVal] -= center \n",
    "    return shift\n",
    "\n",
    "def velCOM(iX,iV):\n",
    "    #compute projected radial velocity (r x v)/|r| \n",
    "    #(note iX[:,0] is the first element of all particles)\n",
    "    #Also note that r x v is radius \"cross\" velocity (aka cros product)\n",
    "    return vproj\n",
    "    \n",
    "def plotRotation(veltracks,tmptracks):\n",
    "    shiftX=shiftCOM(tmptracks[0])\n",
    "    velX=velCOM(shiftX,veltracks[0])\n",
    "    pX0,pY0,pEX0,pEY0 = plotRvsV(np.sqrt(shiftX[:,0]**2+shiftX[:,1]**2),np.abs(velX))\n",
    "    plt.errorbar(pX0,pY0,pEY0,pEX0,marker='v',linestyle='none',label='start',c='blue')\n",
    "    shiftX=shiftCOM(tmptracks[-1])\n",
    "    velX=velCOM(shiftX,veltracks[-1])\n",
    "    pX1,pY1,pEX1,pEY1 = plotRvsV(np.sqrt(shiftX[:,0]**2+shiftX[:,1]**2),np.abs(velX))\n",
    "    plt.errorbar(pX1,pY1,pEY1,pEX1,marker='o',linestyle='none',label='end',c='red')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"R(AU)\")\n",
    "    plt.ylabel(\"V(AU/year)\")\n",
    "    plt.show()\n",
    "\n",
    "tracks=allStar.history()\n",
    "veltracks=allStar.velhistory()\n",
    "plotRotation(veltracks,tracks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326adbe",
   "metadata": {
    "id": "bBCr9cr3KuU7",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.7</span>\n",
    "\n",
    "We know that the discovery of flat rotation curves (flat radial velocity as a function of radius from the galaxy) led to an explanation for dark matter. What is the reason our simulation can produce this effect? Select ALL that apply.\n",
    "\n",
    "A) We are lacking Matter interactoins\\\n",
    "B) We neglect general relativsitic effects\\\n",
    "C) Our softening term doesn’t add other dynamics, it just removes numerial instabilities\\\n",
    "D) Our bodies should have varying mass as well\\\n",
    "E) We didn’t simulate enough stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2edc11",
   "metadata": {
    "id": "bBCr9cr3KuU7",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.5.8</span>\n",
    "\n",
    "Lets simulate a simplified matter galaxy (not dark matter). To do this we need to an insert a force that is not gravitational. What we will do is once the stars get close to each other, we negate the force on them. Namely \n",
    "\n",
    "$$\n",
    "\\forall \\Delta_{ij} < \\epsilon\\\\ \\rightarrow F_{ij} = -F_{ij}^{Grav} = \\frac{G m_{i}m_{j}}{|\\vec{r}_{i}-\\vec{r}_{j}|^3} \\vec{r}_{i}-\\vec{r}_{j}\n",
    "$$\n",
    "\n",
    "The idea is to envision the stars as elastic balls that scatter on each other, the aim here is to emulate a much stronger force that acts locally once the matter is close to each other. In reality this is done treaing the star as a fluid and running a simulation similar to the other probelms. \n",
    "\n",
    "Now modify the force in the code below, and compare the rotation curve. What happens to the ratio of the velocity inner 90% of stars compared to the 10%?\n",
    "\n",
    "Selecto ALL statements that reflect your observations:\n",
    "\n",
    "A) A central core is still formed\\\n",
    "B) Some of the outer stars fly further out of the galaxy\\\n",
    "C) The rotation curve is much (> x2) higher in the central core\\\n",
    "D) The rotation curve appears to have a slightly faster central core, but it is hard to tell\\\n",
    "E) The rotation curve appears to have a slightly denser central core, but it is hard to tell\\\n",
    "F) The stars do not cluster up at all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75119e05",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.5.8\n",
    "\n",
    "#this function computes the force and potential energy of the system\n",
    "def forcefunction(iR,iMass,iSoften):\n",
    "    xpos=iR[:,0:1]\n",
    "    ypos=iR[:,1:2]\n",
    "    dx = xpos.T - xpos\n",
    "    dy = ypos.T - ypos\n",
    "    dr2  = #Add your own code, be sure to add softening\n",
    "    dr1  = dr2**(-0.5)\n",
    "    dr2[dr2>0] = dr2[dr2>0]**(-1.5)\n",
    "    dr2b = #selection on events dr2 < X\n",
    "    dr2[dr2b] =#code to change forces\n",
    "    ax   = #Add your own code\n",
    "    ay   = #Add your own code\n",
    "    a = np.hstack((ax,ay))\n",
    "    pot = -1.*Gmod * dr1 @ iMass\n",
    "    return a,pot\n",
    "\n",
    "nStar=50\n",
    "np.random.seed(1234)\n",
    "X = np.random.uniform(-1,1,(nStar, 2)) * 2e4 \n",
    "V = np.zeros((nStar, 2))\n",
    "M = np.ones((nStar,1))\n",
    "\n",
    "allIntStar = AllStars(X,V,M,ibase=False,isoften=1e3)\n",
    "Xout2=allIntStar.allsteps(insteps=40000,dt=25.)\n",
    "tracks2=allIntStar.history()\n",
    "veltracks2=allIntStar.velhistory()\n",
    "plotRotation(veltracks2,tracks2)\n",
    "plotRadius(tracks2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e69792",
   "metadata": {
    "id": "XwglZZ6LqSnq",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<!--start-block-->\n",
    "<a name='section_4_6'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.6 Training a NN to Find Tau Leptons\n",
    "\n",
    "| [Top](#section_4_0) | [Previous Section](#section_4_5) | [Problems](#problems_4_6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514531d5",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Now we are going to do a classic deep learning classificaiton problem. This uses real simulation that we are using for the current Tau Trigger in the CMS experiment. The strategy here is to build a deep learning algorithm that is small so we can embed this on a special chip that can run this neural network roughly 40 millions times per second to look for tau leptons. The output of this neural network is a probability of whether the object we pass into it is a tau or not. \n",
    "\n",
    "For this training, we will use 1 signal sample consisting of well defined taus from siulated Higgs to tau tau decys, and two backgrounds: the unbiased simulated background called minimum bias, a biased high momentum background sample of jets we will call QCD. The second sample enables the neural network to continue to work at high momentum well. In practice, you will not notice the two background samples, since we merge them for you before hand. Finally, we will train two neural networks a regression, and a discrimintor. This means we will have two truth values we want to train to, the true tau pT for the regression, and separating signal and background. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7690e7",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Data</h3>\n",
    "\n",
    "One data file is located in the `pset4/data` directory in the git repository.\n",
    "\n",
    "You will also need 2 datasets available on dropbox here:\n",
    "* https://www.dropbox.com/scl/fi/kgsxcqdiji7fj8g7k70nx/test_bkg_v12_emseed.root?rlkey=itzrtjvwejqxs7vyzf4k75p0l&dl=0\n",
    "* https://www.dropbox.com/scl/fi/jdljan7gw8bt6n30b0rnm/test_sig_v12_emseed.root?rlkey=w7a5jqifr6u1kx0nm1ktbaq2z&dl=0\n",
    "\n",
    "If you are working locally, download these files and move them to the `pset4/data` directory. If you are working in COLAB, run the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d1e3b",
   "metadata": {
    "id": "06bdc10f",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: P4.0-runcell00\n",
    "\n",
    "#run this cell if using COLAB,\n",
    "#to download the file: test_qcd_v12_emseed.root\n",
    "#NOTE: this will create the directory pset4/data\n",
    "\n",
    "\"\"\"\n",
    "!git init\n",
    "!git remote add -f origin https://github.com/mit-physics-data/psets/\n",
    "!git config core.sparseCheckout true\n",
    "!echo 'pset4/data' >> .git/info/sparse-checkout\n",
    "!git pull origin main\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a089e4",
   "metadata": {
    "scrolled": false,
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "# NOTE: some files are too large to include in the original repository,\n",
    "# so you must download them using the options below\n",
    "#\n",
    "# Ways to download:\n",
    "#     1. Copy/paste the link (replace =0 with =1 to download automatically)\n",
    "#     2. Use the wget commands below (works in Colab, but you may need to install wget if using locally)\n",
    "#\n",
    "# Location of files:\n",
    "#     If working with files locally, move the files to the directory 'data'\n",
    "#\n",
    "# Using wget: (works in Colab)\n",
    "#     Upon downloading, the code below will move them to the appropriate directory: pset4/data\n",
    "\n",
    "\"\"\"\n",
    "#run these lines if using COLAB,\n",
    "#to download the file: test_bkg_v12_emseed.root\n",
    "!wget https://www.dropbox.com/scl/fi/kgsxcqdiji7fj8g7k70nx/test_bkg_v12_emseed.root?rlkey=itzrtjvwejqxs7vyzf4k75p0l&dl=0\n",
    "!mv test_bkg_v12_emseed.root?rlkey=itzrtjvwejqxs7vyzf4k75p0l pset4/data/test_bkg_v12_emseed.root #rename #rename\n",
    "\n",
    "#run these lines if using COLAB,\n",
    "#to download the file: test_sig_v12_emseed.root\n",
    "!wget https://www.dropbox.com/scl/fi/jdljan7gw8bt6n30b0rnm/test_sig_v12_emseed.root?rlkey=w7a5jqifr6u1kx0nm1ktbaq2z&dl=0\n",
    "!mv test_sig_v12_emseed.root?rlkey=w7a5jqifr6u1kx0nm1ktbaq2z pset4/data/test_sig_v12_emseed.root #rename #rename\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb726077",
   "metadata": {
    "scrolled": false,
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#NOTE: install these libraries if you have not done so\n",
    "\n",
    "#!pip install uproot\n",
    "#!pip install pylorentz\n",
    "\n",
    "import random\n",
    "import uproot\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f93308",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "\n",
    "To start with, we will just load the first variable in the dataset, this first variable is the going to be the leading particle momentum in a jet cone of particles. Ultimately, we will load the full 4 vectors and particle ids of the top 10 particles. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f03e0",
   "metadata": {
    "scrolled": false,
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "seed = 1111\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed) \n",
    "\n",
    "def create_train_test_data(dir_path,iNVars=1,maxnum=100000):        \n",
    "    #Might have to change the version for other ntuple files\n",
    "    sig = uproot.open(dir_path+\"data/test_sig_v12_emseed.root\")\n",
    "    bkg = uproot.open(dir_path+\"data/test_bkg_v12_emseed.root\")\n",
    "    qcd = uproot.open(dir_path+\"data/test_qcd_v12_emseed.root\")\n",
    "\n",
    "    sig_input = sig['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    bkg_input = bkg['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    qcd_input = qcd['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "\n",
    "    truth_pt_sig = np.asarray(sig['ntuplePupSingle']['tree']['genpt1'].array())\n",
    "\n",
    "    reco_pt_sig  = sig['ntuplePupSingle']['tree']['pt'].array()\n",
    "    deltaR_sig   = sig['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    eta_sig      = sig['ntuplePupSingle']['tree']['geneta1'].array()\n",
    "    selection_sig = (reco_pt_sig > 12.) & (abs(deltaR_sig) < 0.4) & (abs(eta_sig) < 2.4)\n",
    "    selection_bkg = (bkg['ntuplePupSingle']['tree']['pt'].array() > 12) \n",
    "    selection_qcd = (qcd['ntuplePupSingle']['tree']['pt'].array() > 12)\n",
    "\n",
    "    #Inputs: pt, eta, phi, particle id(one hot encoded)\n",
    "    X_sig = np.nan_to_num(np.asarray(sig_input[selection_sig][0:maxnum]))\n",
    "    Y_sig = np.full(X_sig.shape[0], 1.)\n",
    "\n",
    "    sig_pt = np.asarray(reco_pt_sig[selection_sig][0:maxnum])\n",
    "    Y_sig_pT = truth_pt_sig[selection_sig][0:maxnum]\n",
    "\n",
    "    X_bkg    = np.nan_to_num(np.asarray(bkg_input)[selection_bkg][0:maxnum])\n",
    "    Y_bkg    = np.full(X_bkg.shape[0], 0.)\n",
    "    Y_bkg_pT = np.ones(Y_bkg.shape)\n",
    "    \n",
    "    X_qcd    = np.nan_to_num(np.asarray(qcd_input)[selection_qcd][0:maxnum])\n",
    "    Y_qcd    = np.full(X_qcd.shape[0], 0.)\n",
    "    Y_qcd_pT = np.ones(Y_qcd.shape)\n",
    "    \n",
    "    print(\"Signal Samples\",len(Y_sig),\"label:\",Y_sig[0])\n",
    "    print(\"Bkg Samples\",len(Y_bkg),\"label:\",Y_bkg[0])\n",
    "    print(\"QCD Samples\",len(Y_qcd),\"label:\",Y_qcd[0])\n",
    "    \n",
    "    X_train = np.concatenate([X_sig, X_bkg, X_qcd])\n",
    "    Y_train_tauID = np.concatenate([Y_sig, Y_bkg, Y_qcd])\n",
    "    Y_train_pT    = np.concatenate([Y_sig_pT / sig_pt, Y_bkg_pT, Y_qcd_pT])\n",
    "    \n",
    "    #cleaning\n",
    "    X_train[abs(X_train) > 1e+9] = 0.    \n",
    "    if iNVars > 0:\n",
    "        X_train = X_train[:,0:iNVars]\n",
    "    \n",
    "    #convert to pytorch\n",
    "    X_train       = torch.tensor(X_train, dtype=torch.float32)\n",
    "    Y_train_tauID = torch.tensor(Y_train_tauID, dtype=torch.float32)\n",
    "    Y_train_pT    = torch.tensor(Y_train_pT, dtype=torch.float32)\n",
    "    return X_train, Y_train_tauID, Y_train_pT\n",
    "\n",
    "#set directory path\n",
    "#dir_path = \"pset4/\" #if using colab\n",
    "dir_path = \"\" #if using local directory\n",
    "\n",
    "X_train_tauID, Y_train_tauID,Y_train_pT_regress = create_train_test_data(dir_path)\n",
    "plt.hist(X_train_tauID[:,0][Y_train_tauID == 1],bins=50,range=(0,128),label=\"signal\",alpha=0.5,density=True)\n",
    "plt.hist(X_train_tauID[:,0][Y_train_tauID == 0],bins=50,range=(0,128),label=\"background\",alpha=0.5,density=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8e7aa",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='problems_4_6'></a>     \n",
    "\n",
    "| [Top](#section_4_0) | [Restart Section](#section_4_6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ffc6d",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.1</span>\n",
    "\n",
    "Now we want to make to split the dataset into 3 components so that we can validate the training. These will be \n",
    "\n",
    " * Train => This is the dataset we train the neural network on\n",
    " * Valid => Ths is the dataset that we use to check the loss doesn't overtrain while we train\n",
    " * Test  => This is the dataset that we use to test the performance\n",
    " \n",
    "In the code below, split the data into  20% testing and training, and then split training into a subsequent training and validation with 20% being for valdiation. What yields do you have for testing, training, and validation in `[test,train,validation]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c85297",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.1\n",
    "\n",
    "def splitDataTestValid(iX,iY,test_frac=0.2,val_frac=0.2):\n",
    "    alldataset = torch.utils.data.TensorDataset(iX,iY)\n",
    "    #see https://pytorch.org/docs/stable/data.html\n",
    "    testdataset, trainvaldataset = torch.utils.data.random_split(alldataset, [####,###]) #YOUR CODE HERE\n",
    "    traindataset,valddataset     = torch.utils.data.random_split(trainvaldataset, [###,###]) #YOUR CODE HERE\n",
    "    return testdataset,traindataset,valddataset\n",
    "\n",
    "test,train,valid = splitDataTestValid(X_train_tauID, Y_train_tauID)\n",
    "print(len(test),len(train),len(valid))#note train > test > valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6f739",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.2</span>\n",
    "\n",
    "Ok, now lets create a one layer neural network that applys a sigmoid output to the output of that one layer. Create the network and then apply it directly to the test dataset. What is the mean output? Report a number with precision `1e-3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450864d7",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.2\n",
    "\n",
    "class NN_1layer(torch.nn.Module):\n",
    "    def __init__(self,ninputs):\n",
    "        super().__init__()\n",
    "        self.fc1 = #one linear layer\n",
    "        self.output = #apply a sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "torch.random.manual_seed(1234) \n",
    "test_model = NN_1layer(1)\n",
    "output = test_model(test[:][0])\n",
    "print(output.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc258d10",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.3</span>\n",
    "\n",
    "Ok, now lets compute the loss for this network. Use Binary Cross entropy on the test dataset. What is your loss? Report a number with precision `1e-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549b53e",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.3\n",
    "\n",
    "criterion = ##Add binary cross entropy loss\n",
    "#loss = criterion(label,output.flatten()) ### <===> note this is incorrect, but whas what was in answer key, should be fixed nwo\n",
    "loss = criterion(output.flatten(),label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ea958",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.4</span>\n",
    "\n",
    "Ok, now lets do the whole training loop, we will write a function that takes the loss, model, and trains it with a fixed batchsize using dataloaders. What is the testing, training, validation loss after 10 epochs? Report your answer as a list of number `[test,train,valid]` with precision `1e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eaa2e",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.4\n",
    "\n",
    "def train_model(iModel,iCriterion,iTrain,iValid,nepochs=5,learning_rate=0.01,iBatch=1000):\n",
    "    optimizer   = #Use Adam optimizer with a learning rate of 0.01 \n",
    "    history     = {'loss':[], 'val_loss':[]}\n",
    "    #dataloaders to cache things (not really needed, but good to know)\n",
    "    trainloader = torch.utils.data.DataLoader(iTrain,batch_size=iBatch,shuffle=True)\n",
    "    valloader   = torch.utils.data.DataLoader(iValid,batch_size=iBatch,shuffle=True)\n",
    "    \n",
    "    for epoch in range(nepochs):\n",
    "        current_loss = 0.0 #rezero loss\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = #apply model\n",
    "            loss = #apply loss\n",
    "            #backpropagate loss\n",
    "            #step optimizer\n",
    "            current_loss += loss.item()\n",
    "        \n",
    "            if i == len(trainloader)-1:\n",
    "                current_val_loss = 0.0\n",
    "                with torch.no_grad():#disable updating gradient\n",
    "                    for iv, vdata in enumerate(valloader):\n",
    "                        val_inputs, val_labels = vdata\n",
    "                        val_loss = #validation loss\n",
    "                        current_val_loss += val_loss.item()\n",
    "                    print('[%d, %4d] loss: %.4f  val loss: %.4f' % \n",
    "                          (epoch + 1, i + 1, current_loss/float(i+1) , current_val_loss/float(len(valloader))))\n",
    "                history['loss'].append(current_loss/float(i+1))\n",
    "                history['val_loss'].append(current_val_loss/float(len(valloader)))\n",
    "    return history\n",
    "\n",
    "history=train_model(test_model,criterion,train,valid,nepochs=10)\n",
    "plt.plot(history['loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "testloss=criterion(test_model(test[:][0]),test[:][1])\n",
    "print(testloss,history['loss'][-1],history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adde5d",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.5 </span>\n",
    "\n",
    "Now lets test the performance of this discriminator by computing a ROC curve. To do this, we will\n",
    "\n",
    "a) plot the signal and background output of the neural network\\\n",
    "b) compute the Reciever operator chacteristic\\\n",
    "c) Compute the Area under a curve (AUC)\n",
    "\n",
    "What is the AUC you achieve? Report a number with precision `1e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30063d54",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.5\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "output=#compute the output on thee test dataset\n",
    "label=#labels on the test dataset\n",
    "\n",
    "#now plot it\n",
    "plt.hist(output[label==0].detach().numpy(),histtype='step',color='r',density=True,label='bkg',bins=30)\n",
    "plt.hist(output[label==1].detach().numpy(),histtype='step',color='b',density=True,label='signal',bins=30)\n",
    "plt.xlabel('NN Discriminant')\n",
    "plt.ylabel('N')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def compute_ROC(labels, predicts, npts=501):\n",
    "    cutvals = #make a line from min to max with npoints\n",
    "    tot0 = float(len(labels[labels==0]))#bkg\n",
    "    tot1 = float(len(labels[labels==1]))#sig\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for c in cutvals:\n",
    "        passbkg=#condition for label=0 and prediction > c (aka cutval)\n",
    "        passsig=#condition for label=1 and prediction > c (aka cutval)\n",
    "        fpr.append(float(len(predicts[passbkg]))/tot0)\n",
    "        tpr.append(float(len(predicts[passsig]))/tot1)\n",
    "    return np.array(fpr),np.array(tpr)\n",
    "\n",
    "test_model_roc = compute_ROC(label,output)\n",
    "plt.plot(test_model_roc[0],test_model_roc[1],'g-',label=\"NN\")\n",
    "plt.title(\"ROC (Receiver Operating Characteristic) Curve\")\n",
    "plt.xlabel(\"False Positive Rate (FPR) aka Background Efficiency\")\n",
    "plt.ylabel(\"True Positive Rate (TPR) aka Signal Efficiency\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC:\",metrics.auc(#compute AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb873c53",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.6</span>\n",
    "\n",
    "Ok, Now we have run through a very simple NN. Lets go ahead and load the full dataset and train, start with 10 epochs. The full dataset has 80 inputs, these inputs start form a jet (a cone in a collision):\n",
    "\n",
    " * pT of the first particle\n",
    " * theta (really eta) of the first particle from the center of the jet\n",
    " * phi of the first particle from the center of the jet\n",
    " * one hot coded id of the particle  (this is a vector of 5 elements that are zero or 1)\n",
    "   * [pion, electron, muon, photon, neutral hadron]\n",
    " * the above 8 variables for the top 10 particles in the jet\n",
    " \n",
    "What is the `[test,train,valid]` loss after 10 epochs? Report your answer as a list of numbers with precision `1e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ee4cd",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.6\n",
    "\n",
    "\n",
    "X_train_tauID, Y_train_tauID,Y_train_pT_regress = create_train_test_data(dir_path,iNVars=-1)\n",
    "train,test,valid = splitDataTestValid(X_train_tauID, Y_train_tauID)\n",
    "print(train[:][0].shape)\n",
    "test_model = #make 1 layer NN\n",
    "history=#train this guy\n",
    "plt.plot(history['loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "trainloss=#apply this to the test loss\n",
    "print(testloss,history['loss'][-1],history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62781e0",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.7</span>\n",
    "\n",
    "Ok, Now Lets go ahead and build a 3 layer network with relu activations, and 50 hidden parameters, for the intermediate layers. What is the [test,train,valid] loss after 10 epochs? Report your answer as a list of numbers with precision `2e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140de114",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.7\n",
    "\n",
    "class NN_3layer(torch.nn.Module):\n",
    "    def __init__(self,ninputs):\n",
    "        super().__init__()\n",
    "        self.fc1 = #one linear layer\n",
    "        self.act1 = #Relu activation\n",
    "        self.fc2 = #one linear layer\n",
    "        self.act2 = #Relu activation\n",
    "        self.fc3 = #one linear layer\n",
    "        self.output = #apply a sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "torch.random.manual_seed(1234) \n",
    "test_model = NN_3layer()\n",
    "history=train_model(test_model,criterion,train,valid,nepochs=10)\n",
    "plt.plot(history['loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "testloss=#Test loss\n",
    "print(testloss,history['loss'][-1],history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee774b1",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.8</span>\n",
    "\n",
    "Ok, lets train this guy for another 30 epochs. Again, what is the [test,train,valid] loss after 10 epochs? Report your answer as a list of numbers with precision `2e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ceb94",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.8\n",
    "\n",
    "history=train_model(test_model,criterion,train,valid,nepochs=###)\n",
    "plt.plot(history['loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "testloss=criterion(test_model(test[:][0]).flatten(),test[:][1])\n",
    "print(testloss, history['loss'][-1],history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f5e73",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.9</span>\n",
    "\n",
    "Ok, now plot the ROC curve. What is the AUC? Report your answer as number with precision `1e-2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27aef43",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.10</span>\n",
    "\n",
    "Now apply a cut on the discriminator and compute the efficiency vs. leading particle pt (first input). What is the NN doing? For example, examine the efficiency for pt = 30 GeV and pt = 100 GeV.\n",
    "\n",
    "Try this out, then consider which of the following statements reflect your observations. Select ALL the apply.\n",
    "\n",
    "A) The signal efficiency has a turn on as a function of leading pT getting higher rapidly until its above 80% and then leveling off\\\n",
    "B) The signal efficiency drops quickly and has a small eff ( 50%) at pT > 100 GeV\\\n",
    "C) The signal efficiency is always high ( > 80%) for all pTs even below 20 GeV\\\n",
    "D) The background efficiency peaks at 30 GeV with an efficiency of around 30%\\\n",
    "E) The background efficiency peaks at high pT (> 50 GeV) with an efficiency of around 30%\\\n",
    "F) The backround effiecncy goes above 50% at some pT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a1197",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.10\n",
    "\n",
    "passcut = #cut on NN at crossing point\n",
    "\n",
    "countsS,bins,_ = plt.hist(test[:][0][:,0][###signal],bins=50,range=(0,128),label=\"signal\",alpha=0.5)\n",
    "countsB,bins,_ = plt.hist(test[:][0][:,0][###bkg],bins=50,range=(0,128),label=\"background\",alpha=0.5)\n",
    "countsSC,bins,_ = plt.hist(test[:][0][:,0][(###signal) & passcut],bins=50,range=(0,128),label=\"signal(pass)\",alpha=0.5)\n",
    "countsBC,bins,_ = plt.hist(test[:][0][:,0][(###bkg) & passcut],bins=50,range=(0,128),label=\"background(pass)\",alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"lead pT(GeV)\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.show()\n",
    "\n",
    "bincenter = 0.5*(bins[1:] + bins[:-1])\n",
    "plt.plot(bincenter,countsSC/countsS,marker='.',label='signal')\n",
    "plt.plot(bincenter,countsBC/countsB,marker='.',label='bkg')\n",
    "plt.legend()\n",
    "plt.ylabel('eff')\n",
    "plt.xlabel(\"lead pT(GeV)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cda702",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.6.11</span>\n",
    "\n",
    "Finally, lets see if we can use this NN to find a hidden signal in the data. We will construct a dataset with a mystery mass peak comprising two taus that is injected to background events at the 1.5 percent level (750 events in 50k). Given the output variables of the two taus, find the mass of the hidden signal. Report your answer as a number with precision `1e1`.\n",
    "\n",
    "NOTE: This is hard, especially to do it convincingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db517af",
   "metadata": {
    "scrolled": true,
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.11\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "\n",
    "sig = uproot.open(dir_path + \"data/test_sig_v12_emseed.root\")\n",
    "print(sig['ntuplePupDiTau']['tree'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0463c5",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM: P4.6.11\n",
    "\n",
    "def masscompute(iVec1,iVec2):\n",
    "    tau_1 = Momentum4.m_eta_phi_pt(iVec1[3], iVec1[1], iVec1[2], iVec1[0])\n",
    "    tau_2 = Momentum4.m_eta_phi_pt(iVec2[3], iVec2[1], iVec2[2], iVec2[0])\n",
    "    return (tau_1+tau_2).m\n",
    "\n",
    "    \n",
    "def mass_inputsdset(massfunc,idataset):\n",
    "    mask=(idataset[\"pt2\"].array() > 0)# & abs(idataset[\"eta2\"].array()) < 2.1)\n",
    "    mask=(abs(idataset[\"eta2\"].array()) < 2.1) & mask\n",
    "    varlist=[\"pt1\",\"eta1\",\"phi1\",\"m1\",\"pt2\",\"eta2\",\"phi2\",\"m2\"]\n",
    "    arr=0\n",
    "    idx=0\n",
    "    for x in varlist:\n",
    "        pArr=idataset[x].array(library=\"np\")[mask]\n",
    "        if idx == 0: \n",
    "            arr = pArr\n",
    "            idx = idx + 1\n",
    "        else:\n",
    "            arr=np.vstack((arr,pArr))\n",
    "    arr = arr.T\n",
    "    massc = lambda iarr: massfunc(iarr[0:4],iarr[4:8]) \n",
    "    hmasses = np.array([massc(p) for p in arr[0:50000]])\n",
    "    inputs1 = idataset['m1_inputs'].array()\n",
    "    inputs2 = idataset['m2_inputs'].array()\n",
    "    inputs1 = np.nan_to_num(np.asarray(inputs1)[mask][0:50000])\n",
    "    inputs2 = np.nan_to_num(np.asarray(inputs2)[mask][0:50000])\n",
    "    return hmasses,inputs1,inputs2\n",
    "    \n",
    "def create_double_train_test_data(dir_path):\n",
    "    sig = uproot.open(dir_path+\"data/test_sig_v12_emseed.root\")\n",
    "    bkg = uproot.open(dir_path+\"data/test_bkg_v12_emseed.root\")\n",
    "    mvissig,in1_sig,in2_sig = mass_inputsdset(masscompute,sig['ntuplePupDiTau']['tree'])\n",
    "    mvisbkg,in1_bkg,in2_bkg = mass_inputsdset(masscompute,bkg['ntuplePupDiTau']['tree'])\n",
    "    masscut = ( mvissig > mvissig[0]/1.8) &  (mvissig < mvissig[0]/1.2)\n",
    "    mvissig          = mvissig[masscut]\n",
    "    in1_sig[masscut] = in1_sig[masscut]\n",
    "    in2_sig[masscut] = in2_sig[masscut]\n",
    "    mvis_mix = torch.tensor(np.append(mvisbkg[0:50000],mvissig[0:750]), dtype=torch.float32)\n",
    "    in1_mix  = torch.tensor(np.vstack([in1_bkg[0:50000],in1_sig[0:750]]), dtype=torch.float32)\n",
    "    in2_mix  = torch.tensor(np.vstack([in2_bkg[0:50000],in2_sig[0:750]]), dtype=torch.float32)\n",
    "    return mvis_mix,in1_mix,in2_mix\n",
    "        \n",
    "                        \n",
    "    \n",
    "m_mix,in1_mix,in2_mix= create_double_train_test_data(dir_path)\n",
    "val=0.\n",
    "selection  = #apply NN to both legs and cut\n",
    "plt.hist(m_mix,bins=50,range=(0,200),color='gray',label=\"mix\",alpha=0.5)\n",
    "plt.hist(m_mix[selection],bins=25,range=(0,200),color='blue',label=\"selection\",alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
